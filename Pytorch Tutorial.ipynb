{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4158, 0.6673],\n",
      "        [0.8801, 0.0314]])\n",
      "tensor([[0.5434, 0.6437],\n",
      "        [0.4352, 0.8459]])\n",
      "tensor([[0.9592, 1.3110],\n",
      "        [1.3153, 0.8773]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "y = torch.rand(2, 2)\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item() is only available when tensor has one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9591872096061707\n"
     ]
    }
   ],
   "source": [
    "print(y[0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7501, 0.6308, 0.1928, 0.6969],\n",
      "        [0.6851, 0.3781, 0.6394, 0.6597],\n",
      "        [0.4858, 0.6606, 0.5606, 0.2121],\n",
      "        [0.4153, 0.7170, 0.6659, 0.8289]]) torch.Size([4, 4])\n",
      "tensor([[0.7501, 0.6308, 0.1928, 0.6969, 0.6851, 0.3781, 0.6394, 0.6597, 0.4858,\n",
      "         0.6606, 0.5606, 0.2121, 0.4153, 0.7170, 0.6659, 0.8289]]) torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "a,b=4,4\n",
    "x = torch.rand(a,b)\n",
    "print(x,x.size())\n",
    "y=x.view(1,16)\n",
    "print(y,y.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When one of the values is -1, pytorch will automatically covert -1 to the value that make the product fit to the amount of the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7501, 0.6308],\n",
      "        [0.1928, 0.6969],\n",
      "        [0.6851, 0.3781],\n",
      "        [0.6394, 0.6597],\n",
      "        [0.4858, 0.6606],\n",
      "        [0.5606, 0.2121],\n",
      "        [0.4153, 0.7170],\n",
      "        [0.6659, 0.8289]]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.view(-1,2),x.view(-1,2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting between tensor and numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form tensor to numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember if tenseor is save in the CPU instead of the GPU, then a & b will all be saved in the same memory location, that means if one is changed, the other one will change, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form numpy.array to tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "\n",
    "a+=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use following code to check if your cuda is available, and switching from CPU to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But notice! when you're trying to turn z to a numpy.array, you will get Error because numpy is only available on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-93cccc93d0ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x=torch.ones(5, device = device)\n",
    "    y=torch.ones(5)\n",
    "    y=y.to(device)\n",
    "    z=x+y\n",
    "    z.numpy()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to move z back to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x=torch.ones(5, device = device)\n",
    "    y=torch.ones(5)\n",
    "    y=y.to(device)\n",
    "    z=x+y\n",
    "    z = z.to(\"cpu\")\n",
    "    z.numpy()\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you has a variable in your model that you want to optimize, then you need the gredient so you need to specify requires_grad=True(default is False). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3915, 0.8660, 0.3459], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch will generate a backpropagation which is called \"AddBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3915, 2.8660, 2.3459], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/sample1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we use multiplication, Pytorch will generate a backpropagation which is called \"MulBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.4385, 16.4283, 11.0061], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*2 \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we use mean, Pytorch will generate a backpropagation which is called \"MeanBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.9576, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=z.mean() \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run following code, we can get the gradients in this tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1887, 3.8214, 3.1278])\n"
     ]
    }
   ],
   "source": [
    "z.backward() #dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one thing you should know that in the background it will create a vector_jacobian to caculate the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/vector_jacobian.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we don't run the mean(), we will get an 1 by 3 matrix, which can't call the backward function, because backward function can only be called back for scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.9533,  8.8635,  9.1756], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,requires_grad=True)\n",
    "y=x+2\n",
    "z=y*y*2 \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-40c0c9b0bbab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to give it the gredient argument, so we create an vector of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "y=x+2\n",
    "z=y*y*2 \n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) #dz/zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0661e+00, 1.0928e+01, 1.0672e-02])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevent tensor from tracking the grandients(or the tensor will keep creating backward function when you're running a new operation), here are three ways you can try on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8698, 0.3098, 0.9790], requires_grad=True)\n",
      "tensor([0.8698, 0.3098, 0.9790])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "x.requires_grad_(False)\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2703, 0.8299, 0.8660], requires_grad=True)\n",
      "tensor([0.2703, 0.8299, 0.8660])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "print(x)\n",
    "y=x.detach()\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6355, 0.4803, 0.5042], requires_grad=True)\n",
      "tensor([2.6355, 2.4803, 2.5042])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "print(x)\n",
    "with torch.no_grad():\n",
    "    y = x+2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we call the backward function, the gradient for this tensor will be accumulated into the .grad() attribute which will let their values be summed up and will let the gradients of the tensor be incorrect, so before we start the next iteration or optimization step, we must empty the gradients ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with Autograd & Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x=torch.tensor(1.0)\n",
    "y=torch.tensor(2.0)\n",
    "w=torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass and compute the loss\n",
    "y_hat=w*x\n",
    "loss=(y_hat-y)**2\n",
    "print(loss) \n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.680, loss = 4.79999924\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 4: w = 1.949, loss = 0.12288000\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 6: w = 1.992, loss = 0.00314570\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 8: w = 1.999, loss = 0.00008053\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000206\n",
      "Prediction after traning: f(5) = 9.999\n"
     ]
    }
   ],
   "source": [
    "# f = 2 * x \n",
    "X= np.array([1,2,3,4],dtype=np.float32)\n",
    "Y= np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w=0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss=MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients \n",
    "    dw = gradient(X,Y,y_pred)\n",
    "    \n",
    "#     update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will find out that the Prediction after traning still doesn't equal to the true value, so we modify the n_iters from 10 to 20, and see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.680, loss = 4.79999924\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 4: w = 1.949, loss = 0.12288000\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 6: w = 1.992, loss = 0.00314570\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 8: w = 1.999, loss = 0.00008053\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000206\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 12: w = 2.000, loss = 0.00000005\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 14: w = 2.000, loss = 0.00000000\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 16: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 18: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "epoch 20: w = 2.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = 2 * x \n",
    "X= np.array([1,2,3,4],dtype=np.float32)\n",
    "Y= np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w=0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss=MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients \n",
    "    dw = gradient(X,Y,y_pred)\n",
    "    \n",
    "#     update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then the prediction equals to the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do everything with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 0.450, loss = 67.50000000\n",
      "epoch 11: w = 2.498, loss = 2.61626792\n",
      "epoch 21: w = 2.901, loss = 0.10140543\n",
      "epoch 31: w = 2.981, loss = 0.00393051\n",
      "epoch 41: w = 2.996, loss = 0.00015233\n",
      "epoch 51: w = 2.999, loss = 0.00000590\n",
      "epoch 61: w = 3.000, loss = 0.00000023\n",
      "epoch 71: w = 3.000, loss = 0.00000001\n",
      "epoch 81: w = 3.000, loss = 0.00000000\n",
      "epoch 91: w = 3.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 15.000\n"
     ]
    }
   ],
   "source": [
    "# f = 2 * x \n",
    "X= torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y= torch.tensor([3,6,9,12],dtype=torch.float32)\n",
    "\n",
    "w= torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss=MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "#     zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline: model, loss, and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design model (input,output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "    - forward pass : compute function\n",
    "    - backward pass : gradients\n",
    "    - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before traning: f(5) = -3.614\n",
      "epoch 1: w = 0.553, loss = 108.99124146\n",
      "epoch 11: w = 1.746, loss = 5.09082365\n",
      "epoch 21: w = 1.403, loss = 3.54097795\n",
      "epoch 31: w = 2.077, loss = 1.30052698\n",
      "epoch 41: w = 2.664, loss = 0.23959801\n",
      "epoch 51: w = 2.932, loss = 0.02147231\n",
      "epoch 61: w = 3.006, loss = 0.00097522\n",
      "epoch 71: w = 3.013, loss = 0.00021787\n",
      "epoch 81: w = 3.006, loss = 0.00006494\n",
      "epoch 91: w = 3.002, loss = 0.00000830\n",
      "Prediction after traning: f(5) = 15.001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# f = 2 * x \n",
    "X= torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "Y= torch.tensor([[3],[6],[9],[12]],dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5],dtype=torch.float32)\n",
    "\n",
    "n_samples,n_features = X.shape\n",
    "print(n_samples,n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module): #basically, all \"def\"s in pytorch are realized by inheriting from \"nn.Module\". \n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "#       define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):   # Very important!!! forward(self, *input) in pytorch == def __call__(self),\n",
    "        return self.lin(x)  # and x == the matrix of weights generate by nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    \n",
    "model = LinearRegression(input_size, output_size)\n",
    "    \n",
    "print(f'Prediction before traning: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.02\n",
    "n_iters = 100\n",
    "\n",
    "#     loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "#     update weights\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# model.parameters() is used to get the weights after model do LinearRegression.\n",
    "\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "\n",
    "#     zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b]=model.parameters()\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0004],\n",
       "        [ 6.0005],\n",
       "        [ 9.0006],\n",
       "        [12.0007]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0001041889190674"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40])\n"
     ]
    }
   ],
   "source": [
    "# 備註nn.linear()操作\n",
    "m = nn.Linear(20, 40) #建構一個線性方程式\"y=xA^T+b\", 而(20,40)指的是A的shape, 也就是weights的矩陣\n",
    "input = torch.randn(128, 20) #隨機生成一個128*20的tensor\n",
    "output = m(input) #做矩陣乘法\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design model (input,output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "    - forward pass : compute function\n",
    "    - backward pass : gradients\n",
    "    - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss = 5815.5386\n",
      "epoch: 11, loss = 4307.4888\n",
      "epoch: 21, loss = 3216.8760\n",
      "epoch: 31, loss = 2427.2820\n",
      "epoch: 41, loss = 1855.0376\n",
      "epoch: 51, loss = 1439.9211\n",
      "epoch: 61, loss = 1138.5247\n",
      "epoch: 71, loss = 919.5188\n",
      "epoch: 81, loss = 760.2628\n",
      "epoch: 91, loss = 644.3764\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0],1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer \n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "#     prediction = forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "#     backward pass\n",
    "    loss.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b]=model.parameters()\n",
    "        print(f\"epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# 4) plot\n",
    "predicted = model(X).detach().numpy() #Remove the gradients from the results of the prediction, and turn the results to numpy.array \n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic  Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is normallly used to resolve the classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch: 1, loss = 0.6998\n",
      "epoch: 11, loss = 0.5509\n",
      "epoch: 21, loss = 0.4631\n",
      "epoch: 31, loss = 0.4057\n",
      "epoch: 41, loss = 0.3649\n",
      "epoch: 51, loss = 0.3343\n",
      "epoch: 61, loss = 0.3102\n",
      "epoch: 71, loss = 0.2907\n",
      "epoch: 81, loss = 0.2744\n",
      "epoch: 91, loss = 0.2606\n",
      "epoch: 101, loss = 0.2488\n",
      "epoch: 111, loss = 0.2384\n",
      "epoch: 121, loss = 0.2292\n",
      "epoch: 131, loss = 0.2210\n",
      "epoch: 141, loss = 0.2137\n",
      "epoch: 151, loss = 0.2070\n",
      "epoch: 161, loss = 0.2009\n",
      "epoch: 171, loss = 0.1954\n",
      "epoch: 181, loss = 0.1903\n",
      "epoch: 191, loss = 0.1855\n",
      "epoch: 201, loss = 0.1812\n",
      "epoch: 211, loss = 0.1771\n",
      "epoch: 221, loss = 0.1733\n",
      "epoch: 231, loss = 0.1697\n",
      "epoch: 241, loss = 0.1663\n",
      "epoch: 251, loss = 0.1632\n",
      "epoch: 261, loss = 0.1602\n",
      "epoch: 271, loss = 0.1574\n",
      "epoch: 281, loss = 0.1547\n",
      "epoch: 291, loss = 0.1522\n",
      "accuracy = 0.9211\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "# Scale\n",
    "\n",
    "sc = StandardScaler() # this will make your data's mean equals zero.\n",
    "X_train = sc.fit_transform(X_train)# fit means '擬合'\n",
    "X_test = sc.transform(X_test)      # the reason why here do not need fit is because this is test data, \n",
    "                                   # so we don't want the model to coordinate with test data, or the model will be useless. \n",
    "    \n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0],1)\n",
    "y_test = y_test.view(y_test.shape[0],1)\n",
    "\n",
    "\n",
    "# 1) model\n",
    "#    f = wx + b, sigmoid at the end \n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__() #繼承了LogisticRegression的父級,也就是nn.Module的__init__()\n",
    "#       define layers\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        y_predicted = torch.sigmoid(self.linear(x)) #the reason why we need sigmoid is because y(logit(Oods)) may smaller than 0. \n",
    "        return y_predicted\n",
    "    \n",
    "model =  LogisticRegression(n_features)       \n",
    "\n",
    "# 2) loss and optimizer \n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()  # binary cross-entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epoch = 300\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "#     prediction = forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "#     backward pass\n",
    "    loss.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b]=model.parameters()\n",
    "        print(f\"epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "with torch.no_grad(): # without this code y_predicted.round() will still compute the gradient and track it.\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0]) #compare each item is equaled or not,\n",
    "    \n",
    "print(f'accuracy = {acc:.4f}')\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/logistic_regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/sigmoid.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader - Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "#         data loading\n",
    "        xy=np.loadtxt('./data/wine.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[: , 1:])\n",
    "        self.y = torch.from_numpy(xy[: , [0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "# dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "# len(dataset)\n",
    "        return self.n_samples \n",
    "\n",
    "\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1660e+01, 1.8800e+00, 1.9200e+00, 1.6000e+01, 9.7000e+01, 1.6100e+00,\n",
      "         1.5700e+00, 3.4000e-01, 1.1500e+00, 3.8000e+00, 1.2300e+00, 2.1400e+00,\n",
      "         4.2800e+02],\n",
      "        [1.2080e+01, 1.3900e+00, 2.5000e+00, 2.2500e+01, 8.4000e+01, 2.5600e+00,\n",
      "         2.2900e+00, 4.3000e-01, 1.0400e+00, 2.9000e+00, 9.3000e-01, 3.1900e+00,\n",
      "         3.8500e+02],\n",
      "        [1.3870e+01, 1.9000e+00, 2.8000e+00, 1.9400e+01, 1.0700e+02, 2.9500e+00,\n",
      "         2.9700e+00, 3.7000e-01, 1.7600e+00, 4.5000e+00, 1.2500e+00, 3.4000e+00,\n",
      "         9.1500e+02],\n",
      "        [1.4060e+01, 1.6300e+00, 2.2800e+00, 1.6000e+01, 1.2600e+02, 3.0000e+00,\n",
      "         3.1700e+00, 2.4000e-01, 2.1000e+00, 5.6500e+00, 1.0900e+00, 3.7100e+00,\n",
      "         7.8000e+02]]) tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "178 45\n",
      "epoch 1/2, step 5/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 1/2, step 10/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 1/2, step 15/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 1/2, step 20/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "epoch 1/2, step 25/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 1/2, step 30/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 1/2, step 35/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 1/2, step 40/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 1/2, step 45/45, inputs torch.Size([2, 13]), labels: tensor([[2.],\n",
      "        [2.]])\n",
      "epoch 2/2, step 5/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 2/2, step 10/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "epoch 2/2, step 15/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "epoch 2/2, step 20/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 2/2, step 25/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "epoch 2/2, step 30/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 2/2, step 35/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 2/2, step 40/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 2/2, step 45/45, inputs torch.Size([2, 13]), labels: tensor([[1.],\n",
      "        [3.]])\n",
      "45\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "#         data loading\n",
    "        xy=np.loadtxt('./data/wine.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[: , 1:])\n",
    "        self.y = torch.from_numpy(xy[: , [0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "# dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "# len(dataset)\n",
    "        return self.n_samples \n",
    "\n",
    "\n",
    "    dataset = WineDataset()\n",
    "    dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "    # batch_size 是分成幾批&每批幾個 shuffle = True 是指隨機分配 num_workers 是指有多少workers來處理batches\n",
    "\n",
    "    dataiter = iter(dataloader) # 生成一個迭代物件\n",
    "    data = dataiter.next() # next()必須搭配 iter()\n",
    "    features, labels = data\n",
    "    print(features, labels)\n",
    "\n",
    "\n",
    "\n",
    "# training loop\n",
    "    num_epochs = 2 # 應該要是num_workers的數量, 但num_workers在windows不等於0跑不動\n",
    "    total_samples = len(dataset)\n",
    "    n_iteration = math.ceil(total_samples/4)\n",
    "\n",
    "    print(total_samples, n_iteration)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(dataloader): # enumerate()可列出一个為索引序列及元素的組合\n",
    "#             forward, backward, update\n",
    "            if (i+1)%5 == 0:\n",
    "                print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iteration}, inputs {inputs.shape}, labels: {labels}\")\n",
    "\n",
    "    print(len(dataloader))\n",
    "    print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data from numpy, images to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform = None):\n",
    "#         data loading\n",
    "        xy=np.loadtxt('./data/wine.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "        self.x = xy[: , 1:]\n",
    "        self.y = xy[: , [0]]\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "# dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    " \n",
    "    def __len__(self):\n",
    "# len(dataset)\n",
    "        return self.n_samples \n",
    "\n",
    "class ToTensor: \n",
    "    def __call__(self, sample): \n",
    "        #let ToTensor become a callable Object\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "class Multransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "          \n",
    "    def __call__(self, sample): \n",
    "        #let ToTensor become a callable Object\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "    \n",
    "\n",
    "\n",
    "dataset = WineDataset(transform = None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features),type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), Multransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features),type(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax and Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax activation let the data output from actual value to be probabilities.\n",
    "Notice !!! It can only be used as output layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/softmax_layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax torch tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "output = softmax(x)\n",
    "print('softmax numpy:', output)\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "output = torch.softmax(x, dim=0)\n",
    "print('softmax torch', output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/cross_entropy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 numpy: 0.357\n",
      "loss2 numpy: 2.303\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "# y must be one-hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "\n",
    "Y =  np.array([1, 0, 0])\n",
    "\n",
    "# y_pred has probabilities\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f\"loss1 numpy: {l1:.3f}\")\n",
    "print(f\"loss2 numpy: {l2:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02431126870214939\n",
      "3.4183647632598877\n",
      "tensor([2, 0, 1])\n",
      "tensor([1, 2, 0])\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 9., 5.]),\n",
      "indices=tensor([1, 2, 0]))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
    "# nn.LogSoftmax + nn.NLLLoss\n",
    "# NLLLoss = negative log likelihood loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "Y = torch.tensor([2, 0, 1]) #  n_samples == 3\n",
    "#here maens that [the third value in 1st class, first value in 2nd class, second value in 3rd class] has the maximum\n",
    "\n",
    "# n_samples*n_classes = 3*3\n",
    "Y_pred_good = torch.tensor([[5.0, 1.0, 9.0], [5.0, 1.0, 0.25], [0.0, 7.0, 3.4]]) \n",
    "Y_pred_bad = torch.tensor([[0.5, 3.0, 1.0], [5.0, 1.0, 9.0], [5.0, 1.0, 1.2]])\n",
    "\n",
    "\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "\n",
    "_, prediction1 = torch.max(Y_pred_good, 1)\n",
    "_, prediction2 = torch.max(Y_pred_bad, 1)\n",
    "prediction = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(prediction1)\n",
    "print(prediction2)\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/nn.CrossEntropyLoss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check https://blog.csdn.net/silver1225/article/details/88914652 to deeply understand what is NLLLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check https://zhuanlan.zhihu.com/p/35709485 to learn more about CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Binary problem\n",
    "# option1\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "#         no softmax() at the end\n",
    "#       we must use sigmoid at the end, because we need to restrict our output between 0 & 1\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "# option2\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.ReLu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return y_pred\n",
    "        \n",
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5)\n",
    "criterion = nn.BECLoss() #Binary Cross Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "#         no softmax() at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5, num_classes = 3)\n",
    "criterion = nn.CrossEntropyLoss() #applies softmax & NLLLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Network (Using MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/600], Loss: 0.3665\n",
      "Epoch [1/2], Step [200/600], Loss: 0.3435\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1954\n",
      "Epoch [1/2], Step [400/600], Loss: 0.2261\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1572\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1264\n",
      "Epoch [2/2], Step [100/600], Loss: 0.1001\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0990\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1043\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0380\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1067\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0798\n",
      "Accuracy of the network on the 10000 test images: 96.55 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 2\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape )\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1) # subplot(nrows, ncols, index) index decide where the picture should be place.\n",
    "    plt.imshow(example_data[i][0], cmap='gray') #samples[i][0], [0] means the first channel\n",
    "plt.show()\n",
    "# 100 is the quantity of the samples, 1 means one channel(because these are black and white images), 28,28 means 28*28  \n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) #nn.Linear(size of input, size of output )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() #applies softmax & NLLLoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1) #get the max of the outputs and along the dimension one\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
