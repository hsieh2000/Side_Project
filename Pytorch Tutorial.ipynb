{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4158, 0.6673],\n",
      "        [0.8801, 0.0314]])\n",
      "tensor([[0.5434, 0.6437],\n",
      "        [0.4352, 0.8459]])\n",
      "tensor([[0.9592, 1.3110],\n",
      "        [1.3153, 0.8773]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "x = torch.rand(2, 2)\n",
    "print(x)\n",
    "y = torch.rand(2, 2)\n",
    "print(y)\n",
    "y.add_(x)\n",
    "print(y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The item() is only available when tensor has one element."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9591872096061707\n"
     ]
    }
   ],
   "source": [
    "print(y[0,0].item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7501, 0.6308, 0.1928, 0.6969],\n",
      "        [0.6851, 0.3781, 0.6394, 0.6597],\n",
      "        [0.4858, 0.6606, 0.5606, 0.2121],\n",
      "        [0.4153, 0.7170, 0.6659, 0.8289]]) torch.Size([4, 4])\n",
      "tensor([[0.7501, 0.6308, 0.1928, 0.6969, 0.6851, 0.3781, 0.6394, 0.6597, 0.4858,\n",
      "         0.6606, 0.5606, 0.2121, 0.4153, 0.7170, 0.6659, 0.8289]]) torch.Size([1, 16])\n"
     ]
    }
   ],
   "source": [
    "a,b=4,4\n",
    "x = torch.rand(a,b)\n",
    "print(x,x.size())\n",
    "y=x.view(1,16)\n",
    "print(y,y.size())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When one of the values is -1, pytorch will automatically covert -1 to the value that make the product fit to the amount of the elements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7501, 0.6308],\n",
      "        [0.1928, 0.6969],\n",
      "        [0.6851, 0.3781],\n",
      "        [0.6394, 0.6597],\n",
      "        [0.4858, 0.6606],\n",
      "        [0.5606, 0.2121],\n",
      "        [0.4153, 0.7170],\n",
      "        [0.6659, 0.8289]]) torch.Size([8, 2])\n"
     ]
    }
   ],
   "source": [
    "print(x.view(-1,2),x.view(-1,2).size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# converting between tensor and numpy.array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form tensor to numpy.array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n",
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5)\n",
    "print(a)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remember if tenseor is save in the CPU instead of the GPU, then a & b will all be saved in the same memory location, that means if one is changed, the other one will change, too. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n",
      "[2. 2. 2. 2. 2.]\n"
     ]
    }
   ],
   "source": [
    "a.add_(1)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "form numpy.array to tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n",
      "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)\n",
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "a = np.ones(5)\n",
    "print(a)\n",
    "b = torch.from_numpy(a)\n",
    "print(b)\n",
    "\n",
    "a+=1\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you can use following code to check if your cuda is available, and switching from CPU to GPU."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But notice! when you're trying to turn z to a numpy.array, you will get Error because numpy is only available on CPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-24-93cccc93d0ed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mz\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: can't convert cuda:0 device type tensor to numpy. Use Tensor.cpu() to copy the tensor to host memory first."
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x=torch.ones(5, device = device)\n",
    "    y=torch.ones(5)\n",
    "    y=y.to(device)\n",
    "    z=x+y\n",
    "    z.numpy()\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So we need to move z back to CPU "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2., 2., 2., 2., 2.])\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    x=torch.ones(5, device = device)\n",
    "    y=torch.ones(5)\n",
    "    y=y.to(device)\n",
    "    z=x+y\n",
    "    z = z.to(\"cpu\")\n",
    "    z.numpy()\n",
    "\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever you has a variable in your model that you want to optimize, then you need the gredient so you need to specify requires_grad=True(default is False). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(5,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3915, 0.8660, 0.3459], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,requires_grad=True)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch will generate a backpropagation which is called \"AddBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([2.3915, 2.8660, 2.3459], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y=x+2\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/sample1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we use multiplication, Pytorch will generate a backpropagation which is called \"MulBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.4385, 16.4283, 11.0061], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=y*y*2 \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And if we use mean, Pytorch will generate a backpropagation which is called \"MeanBackward\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(12.9576, grad_fn=<MeanBackward0>)\n"
     ]
    }
   ],
   "source": [
    "z=z.mean() \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run following code, we can get the gradients in this tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3.1887, 3.8214, 3.1278])\n"
     ]
    }
   ],
   "source": [
    "z.backward() #dz/dx\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is one thing you should know that in the background it will create a vector_jacobian to caculate the gradients."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/vector_jacobian.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "if we don't run the mean(), we will get an 1 by 3 matrix, which can't call the backward function, because backward function can only be called back for scalar value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([11.9533,  8.8635,  9.1756], grad_fn=<MulBackward0>)\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,requires_grad=True)\n",
    "y=x+2\n",
    "z=y*y*2 \n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-55-40c0c9b0bbab>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mz\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[0;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    362\u001b[0m                 inputs=inputs)\n\u001b[1;32m--> 363\u001b[1;33m         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    364\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    365\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[1;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    165\u001b[0m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_tensor_or_tensors_to_tuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad_tensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 166\u001b[1;33m     \u001b[0mgrad_tensors_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_make_grads\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_grads_batched\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    167\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mretain_graph\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    168\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\autograd\\__init__.py\u001b[0m in \u001b[0;36m_make_grads\u001b[1;34m(outputs, grads, is_grads_batched)\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrequires_grad\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                     \u001b[1;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"grad can be implicitly created only for scalar outputs\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m                 \u001b[0mnew_grads\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mones_like\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmemory_format\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreserve_format\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "z.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we need to give it the gredient argument, so we create an vector of the same size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "y=x+2\n",
    "z=y*y*2 \n",
    "v = torch.tensor([0.1, 1.0, 0.001], dtype=torch.float32)\n",
    "z.backward(v) #dz/zx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.0661e+00, 1.0928e+01, 1.0672e-02])\n"
     ]
    }
   ],
   "source": [
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prevent tensor from tracking the grandients(or the tensor will keep creating backward function when you're running a new operation), here are three ways you can try on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.8698, 0.3098, 0.9790], requires_grad=True)\n",
      "tensor([0.8698, 0.3098, 0.9790])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3,requires_grad=True)\n",
    "print(x)\n",
    "x.requires_grad_(False)\n",
    "\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.2703, 0.8299, 0.8660], requires_grad=True)\n",
      "tensor([0.2703, 0.8299, 0.8660])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "print(x)\n",
    "y=x.detach()\n",
    "print(y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.6355, 0.4803, 0.5042], requires_grad=True)\n",
      "tensor([2.6355, 2.4803, 2.5042])\n"
     ]
    }
   ],
   "source": [
    "x = torch.rand(3, requires_grad=True)\n",
    "print(x)\n",
    "with torch.no_grad():\n",
    "    y = x+2\n",
    "    print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whenever we call the backward function, the gradient for this tensor will be accumulated into the .grad() attribute which will let their values be summed up and will let the gradients of the tensor be incorrect, so before we start the next iteration or optimization step, we must empty the gradients ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([6., 6., 6., 6.])\n",
      "tensor([9., 9., 9., 9.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n",
      "tensor([3., 3., 3., 3.])\n"
     ]
    }
   ],
   "source": [
    "weights = torch.ones(4, requires_grad=True)\n",
    "\n",
    "for epoch in range(3):\n",
    "    model_output = (weights*3).sum()\n",
    "    model_output.backward()\n",
    "    print(weights.grad)\n",
    "    weights.grad.zero_()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Descent with Autograd & Backpropagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(1., grad_fn=<PowBackward0>)\n",
      "tensor(-2.)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "x=torch.tensor(1.0)\n",
    "y=torch.tensor(2.0)\n",
    "w=torch.tensor(1.0, requires_grad=True)\n",
    "\n",
    "# forward pass and compute the loss\n",
    "y_hat=w*x\n",
    "loss=(y_hat-y)**2\n",
    "print(loss) \n",
    "\n",
    "# backward pass\n",
    "loss.backward()\n",
    "print(w.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.680, loss = 4.79999924\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 4: w = 1.949, loss = 0.12288000\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 6: w = 1.992, loss = 0.00314570\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 8: w = 1.999, loss = 0.00008053\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000206\n",
      "Prediction after traning: f(5) = 9.999\n"
     ]
    }
   ],
   "source": [
    "# f = 2 * x \n",
    "X= np.array([1,2,3,4],dtype=np.float32)\n",
    "Y= np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w=0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss=MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.01\n",
    "n_iters = 10\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients \n",
    "    dw = gradient(X,Y,y_pred)\n",
    "    \n",
    "#     update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "you will find out that the Prediction after traning still doesn't equal to the true value, so we modify the n_iters from 10 to 20, and see what's going on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 1.200, loss = 30.00000000\n",
      "epoch 2: w = 1.680, loss = 4.79999924\n",
      "epoch 3: w = 1.872, loss = 0.76800019\n",
      "epoch 4: w = 1.949, loss = 0.12288000\n",
      "epoch 5: w = 1.980, loss = 0.01966083\n",
      "epoch 6: w = 1.992, loss = 0.00314570\n",
      "epoch 7: w = 1.997, loss = 0.00050332\n",
      "epoch 8: w = 1.999, loss = 0.00008053\n",
      "epoch 9: w = 1.999, loss = 0.00001288\n",
      "epoch 10: w = 2.000, loss = 0.00000206\n",
      "epoch 11: w = 2.000, loss = 0.00000033\n",
      "epoch 12: w = 2.000, loss = 0.00000005\n",
      "epoch 13: w = 2.000, loss = 0.00000001\n",
      "epoch 14: w = 2.000, loss = 0.00000000\n",
      "epoch 15: w = 2.000, loss = 0.00000000\n",
      "epoch 16: w = 2.000, loss = 0.00000000\n",
      "epoch 17: w = 2.000, loss = 0.00000000\n",
      "epoch 18: w = 2.000, loss = 0.00000000\n",
      "epoch 19: w = 2.000, loss = 0.00000000\n",
      "epoch 20: w = 2.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 10.000\n"
     ]
    }
   ],
   "source": [
    "# f = 2 * x \n",
    "X= np.array([1,2,3,4],dtype=np.float32)\n",
    "Y= np.array([2,4,6,8],dtype=np.float32)\n",
    "\n",
    "w=0.0\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss=MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.01\n",
    "n_iters = 20\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients \n",
    "    dw = gradient(X,Y,y_pred)\n",
    "    \n",
    "#     update weights\n",
    "    w -= learning_rate * dw\n",
    "    \n",
    "    if epoch % 1 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "        \n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "then the prediction equals to the true value."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Do everything with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction before traning: f(5) = 0.000\n",
      "epoch 1: w = 0.450, loss = 67.50000000\n",
      "epoch 11: w = 2.498, loss = 2.61626792\n",
      "epoch 21: w = 2.901, loss = 0.10140543\n",
      "epoch 31: w = 2.981, loss = 0.00393051\n",
      "epoch 41: w = 2.996, loss = 0.00015233\n",
      "epoch 51: w = 2.999, loss = 0.00000590\n",
      "epoch 61: w = 3.000, loss = 0.00000023\n",
      "epoch 71: w = 3.000, loss = 0.00000001\n",
      "epoch 81: w = 3.000, loss = 0.00000000\n",
      "epoch 91: w = 3.000, loss = 0.00000000\n",
      "Prediction after traning: f(5) = 15.000\n"
     ]
    }
   ],
   "source": [
    "# f = 2 * x \n",
    "X= torch.tensor([1,2,3,4],dtype=torch.float32)\n",
    "Y= torch.tensor([3,6,9,12],dtype=torch.float32)\n",
    "\n",
    "w= torch.tensor(0.0,dtype=torch.float32,requires_grad=True)\n",
    "\n",
    "# model prediction\n",
    "def forward(x):\n",
    "    return w*x\n",
    "\n",
    "# loss=MSE\n",
    "def loss(y,y_predicted):\n",
    "    return ((y_predicted-y)**2).mean()\n",
    "\n",
    "# gradient\n",
    "# MSE = 1/N * (w*x-y)**2\n",
    "# dJ/dw = 1/N 2x(w*x-y)\n",
    "def gradient(x,y,y_predicted):\n",
    "    return np.dot(2*x, y_predicted-y).mean()\n",
    "\n",
    "print(f'Prediction before traning: f(5) = {forward(5):.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.01\n",
    "n_iters = 100\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = forward(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    with torch.no_grad():\n",
    "        w -= learning_rate * w.grad\n",
    "\n",
    "#     zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"epoch {epoch+1}: w = {w:.3f}, loss = {l:.8f}\")\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {forward(5):.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Pipeline: model, loss, and optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design model (input,output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "    - forward pass : compute function\n",
    "    - backward pass : gradients\n",
    "    - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4 1\n",
      "Prediction before traning: f(5) = -3.614\n",
      "epoch 1: w = 0.553, loss = 108.99124146\n",
      "epoch 11: w = 1.746, loss = 5.09082365\n",
      "epoch 21: w = 1.403, loss = 3.54097795\n",
      "epoch 31: w = 2.077, loss = 1.30052698\n",
      "epoch 41: w = 2.664, loss = 0.23959801\n",
      "epoch 51: w = 2.932, loss = 0.02147231\n",
      "epoch 61: w = 3.006, loss = 0.00097522\n",
      "epoch 71: w = 3.013, loss = 0.00021787\n",
      "epoch 81: w = 3.006, loss = 0.00006494\n",
      "epoch 91: w = 3.002, loss = 0.00000830\n",
      "Prediction after traning: f(5) = 15.001\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "# f = 2 * x \n",
    "X= torch.tensor([[1],[2],[3],[4]],dtype=torch.float32)\n",
    "Y= torch.tensor([[3],[6],[9],[12]],dtype=torch.float32)\n",
    "\n",
    "X_test = torch.tensor([5],dtype=torch.float32)\n",
    "\n",
    "n_samples,n_features = X.shape\n",
    "print(n_samples,n_features)\n",
    "\n",
    "input_size = n_features\n",
    "output_size = n_features\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "class LinearRegression(nn.Module): #basically, all \"def\"s in pytorch are realized by inheriting from \"nn.Module\". \n",
    "    \n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(LinearRegression, self).__init__()\n",
    "#       define layers\n",
    "        self.lin = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):   # Very important!!! forward(self, *input) in pytorch == def __call__(self),\n",
    "        return self.lin(x)  # and x == the matrix of weights generate by nn.Linear(input_dim, output_dim)\n",
    "        \n",
    "    \n",
    "model = LinearRegression(input_size, output_size)\n",
    "    \n",
    "print(f'Prediction before traning: f(5) = {model(X_test).item():.3f}')\n",
    "\n",
    "# training\n",
    "learning_rate = 0.02\n",
    "n_iters = 100\n",
    "\n",
    "#     loss\n",
    "loss = nn.MSELoss()\n",
    "\n",
    "#     update weights\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# model.parameters() is used to get the weights after model do LinearRegression.\n",
    "\n",
    "\n",
    "for epoch in range(n_iters):\n",
    "#     prediction = forward pass\n",
    "    y_pred = model(X)\n",
    "    \n",
    "#     loss\n",
    "    l = loss(Y,y_pred)\n",
    "    \n",
    "#     gradients = backward pass\n",
    "    l.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "\n",
    "#     zero gradients\n",
    "    w.grad.zero_()\n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b]=model.parameters()\n",
    "        print(f\"epoch {epoch+1}: w = {w[0][0].item():.3f}, loss = {l:.8f}\")\n",
    "\n",
    "print(f'Prediction after traning: f(5) = {model(X_test).item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 3.0004],\n",
       "        [ 6.0005],\n",
       "        [ 9.0006],\n",
       "        [12.0007]], grad_fn=<AddmmBackward0>)"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0001041889190674"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w[0][0].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 40])\n"
     ]
    }
   ],
   "source": [
    "# 備註nn.linear()操作\n",
    "m = nn.Linear(20, 40) #建構一個線性方程式\"y=xA^T+b\", 而(20,40)指的是A的shape, 也就是weights的矩陣\n",
    "input = torch.randn(128, 20) #隨機生成一個128*20的tensor\n",
    "output = m(input) #做矩陣乘法\n",
    "print(output.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Design model (input,output size, forward pass)\n",
    "2. Construct loss and optimizer\n",
    "3. Training loop\n",
    "    - forward pass : compute function\n",
    "    - backward pass : gradients\n",
    "    - update weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 1, loss = 5815.5386\n",
      "epoch: 11, loss = 4307.4888\n",
      "epoch: 21, loss = 3216.8760\n",
      "epoch: 31, loss = 2427.2820\n",
      "epoch: 41, loss = 1855.0376\n",
      "epoch: 51, loss = 1439.9211\n",
      "epoch: 61, loss = 1138.5247\n",
      "epoch: 71, loss = 919.5188\n",
      "epoch: 81, loss = 760.2628\n",
      "epoch: 91, loss = 644.3764\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "X_numpy, y_numpy = datasets.make_regression(n_samples=100, n_features=1, noise=20, random_state=1)\n",
    "\n",
    "X = torch.from_numpy(X_numpy.astype(np.float32))\n",
    "y = torch.from_numpy(y_numpy.astype(np.float32))\n",
    "y = y.view(y.shape[0],1)\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "# 1) model\n",
    "\n",
    "input_size = n_features\n",
    "output_size = 1\n",
    "model = nn.Linear(input_size, output_size)\n",
    "\n",
    "# 2) loss and optimizer \n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.MSELoss() \n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epoch = 100\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "#     prediction = forward pass and loss\n",
    "    y_predicted = model(X)\n",
    "    loss = criterion(y_predicted, y)\n",
    "    \n",
    "#     backward pass\n",
    "    loss.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b]=model.parameters()\n",
    "        print(f\"epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "# 4) plot\n",
    "predicted = model(X).detach().numpy() #Remove the gradients from the results of the prediction, and turn the results to numpy.array \n",
    "plt.plot(X_numpy, y_numpy, 'ro')\n",
    "plt.plot(X_numpy, predicted, 'b')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic  Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic Regression is normallly used to resolve the classification problems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569 30\n",
      "epoch: 1, loss = 0.6998\n",
      "epoch: 11, loss = 0.5509\n",
      "epoch: 21, loss = 0.4631\n",
      "epoch: 31, loss = 0.4057\n",
      "epoch: 41, loss = 0.3649\n",
      "epoch: 51, loss = 0.3343\n",
      "epoch: 61, loss = 0.3102\n",
      "epoch: 71, loss = 0.2907\n",
      "epoch: 81, loss = 0.2744\n",
      "epoch: 91, loss = 0.2606\n",
      "epoch: 101, loss = 0.2488\n",
      "epoch: 111, loss = 0.2384\n",
      "epoch: 121, loss = 0.2292\n",
      "epoch: 131, loss = 0.2210\n",
      "epoch: 141, loss = 0.2137\n",
      "epoch: 151, loss = 0.2070\n",
      "epoch: 161, loss = 0.2009\n",
      "epoch: 171, loss = 0.1954\n",
      "epoch: 181, loss = 0.1903\n",
      "epoch: 191, loss = 0.1855\n",
      "epoch: 201, loss = 0.1812\n",
      "epoch: 211, loss = 0.1771\n",
      "epoch: 221, loss = 0.1733\n",
      "epoch: 231, loss = 0.1697\n",
      "epoch: 241, loss = 0.1663\n",
      "epoch: 251, loss = 0.1632\n",
      "epoch: 261, loss = 0.1602\n",
      "epoch: 271, loss = 0.1574\n",
      "epoch: 281, loss = 0.1547\n",
      "epoch: 291, loss = 0.1522\n",
      "accuracy = 0.9211\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import StandardScaler \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# 0) prepare data\n",
    "\n",
    "bc = datasets.load_breast_cancer()\n",
    "X, y = bc.data, bc.target\n",
    "\n",
    "n_samples, n_features = X.shape\n",
    "\n",
    "print(n_samples, n_features)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 1234)\n",
    "\n",
    "# Scale\n",
    "\n",
    "sc = StandardScaler() # this will make your data's mean equals zero.\n",
    "X_train = sc.fit_transform(X_train)# fit means '擬合'\n",
    "X_test = sc.transform(X_test)      # the reason why here do not need fit is because this is test data, \n",
    "                                   # so we don't want the model to coordinate with test data, or the model will be useless. \n",
    "    \n",
    "X_train = torch.from_numpy(X_train.astype(np.float32))\n",
    "X_test = torch.from_numpy(X_test.astype(np.float32))\n",
    "y_train = torch.from_numpy(y_train.astype(np.float32))\n",
    "y_test = torch.from_numpy(y_test.astype(np.float32))\n",
    "\n",
    "y_train = y_train.view(y_train.shape[0],1)\n",
    "y_test = y_test.view(y_test.shape[0],1)\n",
    "\n",
    "\n",
    "# 1) model\n",
    "#    f = wx + b, sigmoid at the end \n",
    "\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, n_input_features):\n",
    "        super(LogisticRegression, self).__init__() #繼承了LogisticRegression的父級,也就是nn.Module的__init__()\n",
    "#       define layers\n",
    "        self.linear = nn.Linear(n_input_features, 1)\n",
    "\n",
    "    def forward(self, x):   \n",
    "        y_predicted = torch.sigmoid(self.linear(x)) #the reason why we need sigmoid is because y(logit(Oods)) may smaller than 0. \n",
    "        return y_predicted\n",
    "    \n",
    "model =  LogisticRegression(n_features)       \n",
    "\n",
    "# 2) loss and optimizer \n",
    "\n",
    "learning_rate = 0.01\n",
    "criterion = nn.BCELoss()  # binary cross-entropy loss\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# 3) training loop\n",
    "n_epoch = 300\n",
    "\n",
    "for epoch in range(n_epoch):\n",
    "#     prediction = forward pass and loss\n",
    "    y_predicted = model(X_train)\n",
    "    loss = criterion(y_predicted, y_train)\n",
    "    \n",
    "#     backward pass\n",
    "    loss.backward() #dl/dw\n",
    "    \n",
    "#     update weights\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "        \n",
    "    \n",
    "    if epoch % 10 == 0:\n",
    "        [w, b]=model.parameters()\n",
    "        print(f\"epoch: {epoch+1}, loss = {loss.item():.4f}\")\n",
    "        \n",
    "with torch.no_grad(): # without this code y_predicted.round() will still compute the gradient and track it.\n",
    "    y_predicted = model(X_test)\n",
    "    y_predicted_cls = y_predicted.round()\n",
    "    acc = y_predicted_cls.eq(y_test).sum() / float(y_test.shape[0]) #compare each item is equaled or not,\n",
    "    \n",
    "print(f'accuracy = {acc:.4f}')\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/logistic_regression.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/sigmoid.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset and DataLoader - Batch Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1.4230e+01, 1.7100e+00, 2.4300e+00, 1.5600e+01, 1.2700e+02, 2.8000e+00,\n",
      "        3.0600e+00, 2.8000e-01, 2.2900e+00, 5.6400e+00, 1.0400e+00, 3.9200e+00,\n",
      "        1.0650e+03]) tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "    def __init__(self):\n",
    "#         data loading\n",
    "        xy=np.loadtxt('./data/wine.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[: , 1:])\n",
    "        self.y = torch.from_numpy(xy[: , [0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "# dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "# len(dataset)\n",
    "        return self.n_samples \n",
    "\n",
    "\n",
    "dataset = WineDataset()\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features, labels)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.2250e+01, 1.7300e+00, 2.1200e+00, 1.9000e+01, 8.0000e+01, 1.6500e+00,\n",
      "         2.0300e+00, 3.7000e-01, 1.6300e+00, 3.4000e+00, 1.0000e+00, 3.1700e+00,\n",
      "         5.1000e+02],\n",
      "        [1.1870e+01, 4.3100e+00, 2.3900e+00, 2.1000e+01, 8.2000e+01, 2.8600e+00,\n",
      "         3.0300e+00, 2.1000e-01, 2.9100e+00, 2.8000e+00, 7.5000e-01, 3.6400e+00,\n",
      "         3.8000e+02],\n",
      "        [1.3230e+01, 3.3000e+00, 2.2800e+00, 1.8500e+01, 9.8000e+01, 1.8000e+00,\n",
      "         8.3000e-01, 6.1000e-01, 1.8700e+00, 1.0520e+01, 5.6000e-01, 1.5100e+00,\n",
      "         6.7500e+02],\n",
      "        [1.3240e+01, 2.5900e+00, 2.8700e+00, 2.1000e+01, 1.1800e+02, 2.8000e+00,\n",
      "         2.6900e+00, 3.9000e-01, 1.8200e+00, 4.3200e+00, 1.0400e+00, 2.9300e+00,\n",
      "         7.3500e+02]]) tensor([[2.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "178 45\n",
      "epoch 1/4, step 5/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 1/4, step 10/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 1/4, step 15/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 1/4, step 20/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "epoch 1/4, step 25/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 1/4, step 30/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "epoch 1/4, step 35/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 1/4, step 40/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "epoch 1/4, step 45/45, inputs torch.Size([2, 13]), labels: tensor([[2.],\n",
      "        [3.]])\n",
      "epoch 2/4, step 5/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "epoch 2/4, step 10/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 2/4, step 15/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 2/4, step 20/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 2/4, step 25/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 2/4, step 30/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [1.]])\n",
      "epoch 2/4, step 35/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 2/4, step 40/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "epoch 2/4, step 45/45, inputs torch.Size([2, 13]), labels: tensor([[1.],\n",
      "        [2.]])\n",
      "epoch 3/4, step 5/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 3/4, step 10/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [3.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 3/4, step 15/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 3/4, step 20/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "epoch 3/4, step 25/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [3.]])\n",
      "epoch 3/4, step 30/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [3.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "epoch 3/4, step 35/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [2.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "epoch 3/4, step 40/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [1.],\n",
      "        [3.],\n",
      "        [2.]])\n",
      "epoch 3/4, step 45/45, inputs torch.Size([2, 13]), labels: tensor([[3.],\n",
      "        [2.]])\n",
      "epoch 4/4, step 5/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [2.]])\n",
      "epoch 4/4, step 10/45, inputs torch.Size([4, 13]), labels: tensor([[3.],\n",
      "        [3.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 4/4, step 15/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 4/4, step 20/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [1.]])\n",
      "epoch 4/4, step 25/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 4/4, step 30/45, inputs torch.Size([4, 13]), labels: tensor([[1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [1.]])\n",
      "epoch 4/4, step 35/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [2.]])\n",
      "epoch 4/4, step 40/45, inputs torch.Size([4, 13]), labels: tensor([[2.],\n",
      "        [2.],\n",
      "        [1.],\n",
      "        [3.]])\n",
      "epoch 4/4, step 45/45, inputs torch.Size([2, 13]), labels: tensor([[3.],\n",
      "        [1.]])\n",
      "45\n",
      "178\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self):\n",
    "#         data loading\n",
    "        xy=np.loadtxt('./data/wine.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "        self.x = torch.from_numpy(xy[: , 1:])\n",
    "        self.y = torch.from_numpy(xy[: , [0]])\n",
    "        self.n_samples = xy.shape[0]\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "# dataset[0]\n",
    "        return self.x[index], self.y[index]\n",
    "\n",
    "    def __len__(self):\n",
    "# len(dataset)\n",
    "        return self.n_samples \n",
    "\n",
    "\n",
    "    dataset = WineDataset()\n",
    "    dataloader = DataLoader(dataset = dataset, batch_size = 4, shuffle = True, num_workers = 0)\n",
    "    # batch_size 是分成幾批 shuffle = True 是指隨機分配 num_workers 是指有多少workers來處理batches\n",
    "\n",
    "    dataiter = iter(dataloader) # 生成一個迭代物件\n",
    "    data = dataiter.next() # next()必須搭配 iter()\n",
    "    features, labels = data\n",
    "    print(features, labels)\n",
    "\n",
    "\n",
    "\n",
    "# training loop\n",
    "    num_epochs = 4 # 是指要將資料訓練幾個循環\n",
    "    total_samples = len(dataset)\n",
    "    n_iteration = math.ceil(total_samples/4)\n",
    "\n",
    "    print(total_samples, n_iteration)\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (inputs, labels) in enumerate(dataloader): # enumerate()可列出一个為索引序列及元素的組合\n",
    "#             forward, backward, update\n",
    "            if (i+1)%5 == 0:\n",
    "                print(f\"epoch {epoch+1}/{num_epochs}, step {i+1}/{n_iteration}, inputs {inputs.shape}, labels: {labels}\")\n",
    "\n",
    "    print(len(dataloader))\n",
    "    print(len(dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert data from numpy, images to tensors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n",
      " 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n",
      "<class 'numpy.ndarray'> <class 'numpy.ndarray'>\n",
      "tensor([2.8460e+01, 3.4200e+00, 4.8600e+00, 3.1200e+01, 2.5400e+02, 5.6000e+00,\n",
      "        6.1200e+00, 5.6000e-01, 4.5800e+00, 1.1280e+01, 2.0800e+00, 7.8400e+00,\n",
      "        2.1300e+03])\n",
      "<class 'torch.Tensor'> <class 'torch.Tensor'>\n"
     ]
    }
   ],
   "source": [
    "class WineDataset(Dataset):\n",
    "\n",
    "    def __init__(self, transform = None):\n",
    "#         data loading\n",
    "        xy=np.loadtxt('./data/wine.csv', delimiter=\",\",dtype=np.float32,skiprows=1)\n",
    "        self.x = xy[: , 1:]\n",
    "        self.y = xy[: , [0]]\n",
    "        self.n_samples = xy.shape[0]\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __getitem__(self,index):\n",
    "# dataset[0]\n",
    "        sample = self.x[index], self.y[index]\n",
    "    \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample\n",
    " \n",
    "    def __len__(self):\n",
    "# len(dataset)\n",
    "        return self.n_samples \n",
    "\n",
    "class ToTensor: \n",
    "    def __call__(self, sample): \n",
    "        #let ToTensor become a callable Object\n",
    "        inputs, targets = sample\n",
    "        return torch.from_numpy(inputs), torch.from_numpy(targets)\n",
    "    \n",
    "class Multransform:\n",
    "    def __init__(self, factor):\n",
    "        self.factor = factor\n",
    "          \n",
    "    def __call__(self, sample): \n",
    "        #let ToTensor become a callable Object\n",
    "        inputs, targets = sample\n",
    "        inputs *= self.factor\n",
    "        return inputs, targets\n",
    "    \n",
    "\n",
    "\n",
    "dataset = WineDataset(transform = None)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features),type(labels))\n",
    "\n",
    "composed = torchvision.transforms.Compose([ToTensor(), Multransform(2)])\n",
    "dataset = WineDataset(transform = composed)\n",
    "first_data = dataset[0]\n",
    "features, labels = first_data\n",
    "print(features)\n",
    "print(type(features),type(labels))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Softmax and Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Softmax activation let the data output from actual value to be probabilities.\n",
    "Notice !!! It can only be used as output layer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/softmax.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/softmax_layer.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "softmax numpy: [0.65900114 0.24243297 0.09856589]\n",
      "softmax torch tensor([0.6590, 0.2424, 0.0986])\n"
     ]
    }
   ],
   "source": [
    "def softmax(x):\n",
    "    return np.exp(x)/np.sum(np.exp(x), axis = 0)\n",
    "\n",
    "x = np.array([2.0, 1.0, 0.1])\n",
    "output = softmax(x)\n",
    "print('softmax numpy:', output)\n",
    "\n",
    "x = torch.tensor([2.0, 1.0, 0.1])\n",
    "output = torch.softmax(x, dim=0)\n",
    "print('softmax torch', output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/cross_entropy.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss1 numpy: 0.357\n",
      "loss2 numpy: 2.303\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "def cross_entropy(actual, predicted):\n",
    "    loss = -np.sum(actual * np.log(predicted))\n",
    "    return loss # / float(predicted.shape[0])\n",
    "\n",
    "# y must be one-hot encoded\n",
    "# if class 0: [1 0 0]\n",
    "# if class 1: [0 1 0]\n",
    "# if class 2: [0 0 1]\n",
    "\n",
    "Y =  np.array([1, 0, 0])\n",
    "\n",
    "# y_pred has probabilities\n",
    "Y_pred_good = np.array([0.7, 0.2, 0.1])\n",
    "Y_pred_bad = np.array([0.1, 0.3, 0.6])\n",
    "l1 = cross_entropy(Y, Y_pred_good)\n",
    "l2 = cross_entropy(Y, Y_pred_bad)\n",
    "print(f\"loss1 numpy: {l1:.3f}\")\n",
    "print(f\"loss2 numpy: {l2:.3f}\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.02431126870214939\n",
      "3.4183647632598877\n",
      "tensor([2, 0, 1])\n",
      "tensor([1, 2, 0])\n",
      "torch.return_types.max(\n",
      "values=tensor([3., 9., 5.]),\n",
      "indices=tensor([1, 2, 0]))\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "\n",
    "# CrossEntropyLoss in PyTorch (applies Softmax)\n",
    "# nn.LogSoftmax + nn.NLLLoss\n",
    "# NLLLoss = negative log likelihood loss\n",
    "loss = nn.CrossEntropyLoss()\n",
    "\n",
    "\n",
    "Y = torch.tensor([2, 0, 1]) #  n_samples == 3\n",
    "#here maens that [the third value in 1st class, first value in 2nd class, second value in 3rd class] has the maximum\n",
    "\n",
    "# n_samples*n_classes = 3*3\n",
    "Y_pred_good = torch.tensor([[5.0, 1.0, 9.0], [5.0, 1.0, 0.25], [0.0, 7.0, 3.4]]) \n",
    "Y_pred_bad = torch.tensor([[0.5, 3.0, 1.0], [5.0, 1.0, 9.0], [5.0, 1.0, 1.2]])\n",
    "\n",
    "\n",
    "\n",
    "l1 = loss(Y_pred_good, Y)\n",
    "l2 = loss(Y_pred_bad, Y)\n",
    "\n",
    "print(l1.item())\n",
    "print(l2.item())\n",
    "\n",
    "_, prediction1 = torch.max(Y_pred_good, 1)\n",
    "_, prediction2 = torch.max(Y_pred_bad, 1)\n",
    "prediction = torch.max(Y_pred_bad, 1)\n",
    "\n",
    "print(prediction1)\n",
    "print(prediction2)\n",
    "print(prediction)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/nn.CrossEntropyLoss.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check https://blog.csdn.net/silver1225/article/details/88914652 to deeply understand what is NLLLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can check https://zhuanlan.zhihu.com/p/35709485 to learn more about CrossEntropyLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# Binary problem\n",
    "# option1\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "#         no softmax() at the end\n",
    "#       we must use sigmoid at the end, because we need to restrict our output between 0 & 1\n",
    "        y_pred = torch.sigmoid(out)\n",
    "        return y_pred\n",
    "\n",
    "# option2\n",
    "class NeuralNet1(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.linear2 = nn.Linear(hidden_size, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = torch.ReLu(self.linear1(x))\n",
    "        out = torch.sigmoid(self.linear2(out))\n",
    "        return y_pred\n",
    "        \n",
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5)\n",
    "criterion = nn.BECLoss() #Binary Cross Entropy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "\n",
    "# multiclass problem\n",
    "class NeuralNet2(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet2, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "#         no softmax() at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet2(input_size = 28*28, hidden_size = 5, num_classes = 3)\n",
    "criterion = nn.CrossEntropyLoss() #applies softmax & NLLLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feed-Forward Neural Network (Using MNIST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([100, 1, 28, 28]) torch.Size([100])\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 6 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/600], Loss: 0.2367\n",
      "Epoch [1/3], Step [200/600], Loss: 0.2989\n",
      "Epoch [1/3], Step [300/600], Loss: 0.2266\n",
      "Epoch [1/3], Step [400/600], Loss: 0.1305\n",
      "Epoch [1/3], Step [500/600], Loss: 0.2382\n",
      "Epoch [1/3], Step [600/600], Loss: 0.1387\n",
      "Epoch [2/3], Step [100/600], Loss: 0.1782\n",
      "Epoch [2/3], Step [200/600], Loss: 0.1191\n",
      "Epoch [2/3], Step [300/600], Loss: 0.1174\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0630\n",
      "Epoch [2/3], Step [500/600], Loss: 0.1148\n",
      "Epoch [2/3], Step [600/600], Loss: 0.1066\n",
      "Epoch [3/3], Step [100/600], Loss: 0.0381\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0898\n",
      "Epoch [3/3], Step [300/600], Loss: 0.0738\n",
      "Epoch [3/3], Step [400/600], Loss: 0.0337\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0599\n",
      "Epoch [3/3], Step [600/600], Loss: 0.1015\n",
      "Accuracy of the network on the 10000 test images: 97.7 %\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Device configuration\n",
    "# device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device = torch.device('cpu')\n",
    "\n",
    "# Hyper-parameters \n",
    "input_size = 784 # 28x28\n",
    "hidden_size = 500 \n",
    "num_classes = 10\n",
    "num_epochs = 3\n",
    "batch_size = 100\n",
    "learning_rate = 0.001\n",
    "\n",
    "# MNIST dataset \n",
    "train_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                           train=True, \n",
    "                                           transform=transforms.ToTensor(),  \n",
    "                                           download=True)\n",
    "\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', \n",
    "                                          train=False, \n",
    "                                          transform=transforms.ToTensor())\n",
    "\n",
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, \n",
    "                                           batch_size=batch_size, \n",
    "                                           shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, \n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=False)\n",
    "\n",
    "examples = iter(test_loader)\n",
    "samples, labels = examples.next()\n",
    "print(samples.shape, labels.shape )\n",
    "\n",
    "for i in range(6):\n",
    "    plt.subplot(2,3,i+1) # subplot(nrows, ncols, index) index decide where the picture should be place.\n",
    "    plt.imshow(samples[i][0], cmap='gray') #samples[i][0], [0] means the first channel\n",
    "plt.show()\n",
    "# 100 is the batches of the samples, 1 means one channel(because these are black and white images), 28,28 means 28*28  \n",
    "\n",
    "\n",
    "# Fully connected neural network with one hidden layer\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_classes):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.l1 = nn.Linear(input_size, hidden_size) #nn.Linear(size of input, size of output )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.l2 = nn.Linear(hidden_size, num_classes)  \n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = self.l1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.l2(out)\n",
    "        # no activation and no softmax at the end\n",
    "        return out\n",
    "\n",
    "model = NeuralNet(input_size, hidden_size, num_classes).to(device)\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss() #applies softmax & NLLLoss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "# Train the model\n",
    "n_total_steps = len(train_loader)\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):  \n",
    "        # origin shape: [100, 1, 28, 28]\n",
    "        # resized: [100, 784]\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Test the model\n",
    "# In test phase, we don't need to compute gradients (for memory efficiency)\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    for images, labels in test_loader:\n",
    "        images = images.reshape(-1, 28*28).to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1) #get the max of the outputs and along the dimension one\n",
    "        n_samples += labels.shape[0]\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network on the 10000 test images: {acc} %')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/CNN.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/CNN2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![jupyter](./images/Maxpooling.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pooling not only reduce the cost of computing but also let the input become abstract, which will reduce the possibility of over-fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 3, 32, 32])\n",
      "torch.Size([4, 6, 28, 28])\n",
      "torch.Size([4, 6, 14, 14])\n",
      "torch.Size([4, 16, 10, 10])\n",
      "torch.Size([4, 16, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import ssl\n",
    "ssl._create_default_https_context = ssl._create_unverified_context\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "# device = torch.device('cpu')\n",
    "\n",
    "\n",
    "# Hyper-parameters \n",
    "num_epochs = 5\n",
    "batch_size = 4\n",
    "learning_rate = 0.001\n",
    "\n",
    "# dataset has PILImage images of range [0, 1]. \n",
    "# We transform them to Tensors of normalized range [-1, 1]\n",
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "# CIFAR10: 60000 32x32 color images in 10 classes, with 6000 images per class\n",
    "train_dataset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size,\n",
    "                                          shuffle=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size,\n",
    "                                         shuffle=False)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def imshow(img):\n",
    "    img = img / 2 + 0.5  # unnormalize\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.show()\n",
    "    \n",
    "\n",
    "\n",
    "# get some random training images\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# show images\n",
    "imshow(torchvision.utils.make_grid(images))\n",
    "\n",
    "# to show how class ConvNet's arguments be assign \n",
    "conv1 = nn.Conv2d(3, 6, 5)\n",
    "pool = nn.MaxPool2d(2, 2)\n",
    "conv2 = nn.Conv2d(6, 16, 5)\n",
    "print(images.shape)\n",
    "x = conv1(images)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "x = conv2(x)\n",
    "print(x.shape)\n",
    "x = pool(x)\n",
    "print(x.shape)\n",
    "\n",
    "# implement convolutional neural network\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)# nn.Conv2d(input_channel_size, output_channel_size, kernel_size)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # -> n, 3, 32, 32\n",
    "        x = self.pool(F.relu(self.conv1(x)))  # -> n, 6, 14, 14\n",
    "        x = self.pool(F.relu(self.conv2(x)))  # -> n, 16, 5, 5\n",
    "        x = x.view(-1, 16 * 5 * 5)            # -> n, 400\n",
    "        x = F.relu(self.fc1(x))               # -> n, 120\n",
    "        x = F.relu(self.fc2(x))               # -> n, 84\n",
    "        x = self.fc3(x)                       # -> n, 10\n",
    "        return x\n",
    "\n",
    "\n",
    "model = ConvNet().to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "n_total_steps = len(train_loader)\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (images, labels) in enumerate(train_loader):\n",
    "        # origin shape: [4, 3, 32, 32] = 4, 3, 1024\n",
    "        # input_layer: 3 input channels, 6 output channels, 5 kernel size\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (i+1) % 2000 == 0:\n",
    "            print (f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{n_total_steps}], Loss: {loss.item():.4f}')\n",
    "\n",
    "print('Finished Training')\n",
    "PATH = './cnn.pth'\n",
    "torch.save(model.state_dict(), PATH)\n",
    "\n",
    "with torch.no_grad():\n",
    "    n_correct = 0\n",
    "    n_samples = 0\n",
    "    n_class_correct = [0 for i in range(10)]\n",
    "    n_class_samples = [0 for i in range(10)]\n",
    "    for images, labels in test_loader:\n",
    "        images = images.to(device)\n",
    "        labels = labels.to(device)\n",
    "        outputs = model(images)\n",
    "        # max returns (value ,index)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        n_samples += labels.size(0)\n",
    "        n_correct += (predicted == labels).sum().item()\n",
    "        \n",
    "        for i in range(batch_size):\n",
    "            label = labels[i]\n",
    "            pred = predicted[i]\n",
    "            if (label == pred):\n",
    "                n_class_correct[label] += 1\n",
    "            n_class_samples[label] += 1\n",
    "\n",
    "    acc = 100.0 * n_correct / n_samples\n",
    "    print(f'Accuracy of the network: {acc} %')\n",
    "\n",
    "    for i in range(10):\n",
    "        acc = 100.0 * n_class_correct[i] / n_class_samples[i]\n",
    "        print(f'Accuracy of {classes[i]}: {acc} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
